{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('data', 'mnist', 'mnist.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import raw data\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "with gzip.open(path, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), unknown) = pickle.load(f, encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = torch.nn.Linear(784, 128)\n",
    "        self.hidden2 = torch.nn.Linear(128, 256)\n",
    "        self.out = torch.nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.hidden1(x))\n",
    "        x = torch.nn.functional.relu(self.hidden2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test data\n",
    "train_ds = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size = 128, shuffle = True)\n",
    "\n",
    "valid_ds = torch.utils.data.TensorDataset(x_valid, y_valid)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds):\n",
    "    return (torch.utils.data.DataLoader(train_ds, batch_size = 128, shuffle = True), \n",
    "           torch.utils.data.DataLoader(valid_ds, batch_size = 256))\n",
    "\n",
    "def get_model():\n",
    "    model = Mnist_model()\n",
    "    return model\n",
    "\n",
    "def get_optim(model):\n",
    "    return torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt = None):\n",
    "    # also optimizer\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def fit(steps, model, loss_func, train_dl, valid_dl):\n",
    "    for step in range(steps):\n",
    "        # set model in train mode\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt = get_optim(model))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip( *[loss_batch(model, loss_func, xb, yb) \n",
    "                                  for xb, yb in valid_dl])\n",
    "            valid_loss = np.sum(np.multiply(losses, nums) / np.sum(nums))\n",
    "            \n",
    "        print('Step: {}, loss: {}'.format(step, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, loss: 2.2936904724121097\n",
      "Step: 1, loss: 2.2830302268981937\n",
      "Step: 2, loss: 2.271281169128418\n",
      "Step: 3, loss: 2.2573572257995607\n",
      "Step: 4, loss: 2.240075008010864\n",
      "Step: 5, loss: 2.21809147644043\n",
      "Step: 6, loss: 2.189735460281372\n",
      "Step: 7, loss: 2.1529442615509033\n",
      "Step: 8, loss: 2.104997978210449\n",
      "Step: 9, loss: 2.042851379776001\n",
      "Step: 10, loss: 1.9635436347961428\n",
      "Step: 11, loss: 1.8654697584152222\n",
      "Step: 12, loss: 1.7495662075042726\n",
      "Step: 13, loss: 1.6200777475357055\n",
      "Step: 14, loss: 1.483881675720215\n",
      "Step: 15, loss: 1.349219493675232\n",
      "Step: 16, loss: 1.2235611444473267\n",
      "Step: 17, loss: 1.1116140420913696\n",
      "Step: 18, loss: 1.0146974981307983\n",
      "Step: 19, loss: 0.9322955263137818\n",
      "Step: 20, loss: 0.8629566877365112\n",
      "Step: 21, loss: 0.8038945945739746\n",
      "Step: 22, loss: 0.7538351017951965\n",
      "Step: 23, loss: 0.7107317025184632\n",
      "Step: 24, loss: 0.6738278924942016\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds)\n",
    "model = get_model()\n",
    "fit(25, model, loss_func, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x12f6fafd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
